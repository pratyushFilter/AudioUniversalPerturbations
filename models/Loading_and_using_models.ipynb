{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.framework.python.ops import audio_ops as contrib_audio\n",
    "\n",
    "import scipy.io.wavfile as wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Heper function to load frozen graphs\n",
    "def load_graph(frozen_graph_filename):\n",
    "    with tf.gfile.GFile(frozen_graph_filename, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def, name=\"prefix\")\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#List of output labels:\n",
    "# 0 --> \"Silence\"\n",
    "# 1 --> \"Unknown\"\n",
    "# ...\n",
    "labels = [\"_silence_\", \"_unknown_\", \"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Model A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model graph...\n",
      "Graph loaded!\n",
      "Tensors restored! Initialization successfully completed!\n"
     ]
    }
   ],
   "source": [
    "model_path = \"target_model_A.pb\"\n",
    "\n",
    "print(\"Loading model graph...\")\n",
    "graph = load_graph(model_path)\n",
    "sess = tf.Session(graph=graph)\n",
    "print(\"Graph loaded!\")\n",
    "\n",
    "input_layer_name   = \"prefix/input_audio:0\"    #INPUT TENSOR NAME\n",
    "logits_layer_name  = \"prefix/add_3:0\"          #LOGITS TENSOR NAME\n",
    "softmax_layer_name = \"prefix/labels_softmax:0\" #SOFTMAX TENSOR NAME\n",
    "\n",
    "input_tensor   = graph.get_tensor_by_name(input_layer_name)   #LOGITS TENSOR\n",
    "logits_tensor  = graph.get_tensor_by_name(logits_layer_name)  #LOGITS TENSOR\n",
    "softmax_tensor = graph.get_tensor_by_name(softmax_layer_name) #SOFTMAX TENSOR\n",
    "print(\"Tensors restored! Initialization successfully completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the audio signal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "audio_path = \"audio_sample.wav\"\n",
    "fs, audio = wav.read(audio_path)\n",
    "\n",
    "#Scale the audio signal in the range [-1,1]\n",
    "scale_factor = 1/(1<<15)\n",
    "audio_scaled = audio*scale_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 2 (yes)\n",
      "Softmax:\n",
      "[5.5938585e-07 3.6236126e-04 9.7854769e-01 1.6078235e-03 9.9004319e-06\n",
      " 2.1291213e-04 1.8560080e-02 3.1827876e-04 2.0673940e-07 3.0109470e-04\n",
      " 2.2496099e-05 5.6669429e-05]\n"
     ]
    }
   ],
   "source": [
    "softmax = sess.run(softmax_tensor,  feed_dict={input_tensor: audio_scaled.reshape(1,16000)}).flatten()\n",
    "prediction = np.argmax(softmax)      \n",
    "\n",
    "print(\"Predicted class: %d (%s)\"%(prediction, labels[prediction]))\n",
    "print(\"Softmax:\")\n",
    "print(softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Model B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model graph...\n",
      "Graph loaded!\n",
      "Tensors restored! Initialization successfully completed!\n"
     ]
    }
   ],
   "source": [
    "model_path = \"target_model_B.pb\"\n",
    "\n",
    "print(\"Loading model graph...\")\n",
    "graph = load_graph(model_path)\n",
    "sess = tf.Session(graph=graph)\n",
    "print(\"Graph loaded!\")\n",
    "\n",
    "input_layer_name   = \"prefix/wav_data:0\"       #INPUT TENSOR NAME\n",
    "logits_layer_name  = \"prefix/add_2:0\"          #LOGITS TENSOR NAME\n",
    "softmax_layer_name = \"prefix/labels_softmax:0\" #SOFTMAX TENSOR NAME\n",
    "\n",
    "input_tensor   = graph.get_tensor_by_name(input_layer_name)   #LOGITS TENSOR\n",
    "logits_tensor  = graph.get_tensor_by_name(logits_layer_name)  #LOGITS TENSOR\n",
    "softmax_tensor = graph.get_tensor_by_name(softmax_layer_name) #SOFTMAX TENSOR\n",
    "print(\"Tensors restored! Initialization successfully completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the audio signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "audio_path = \"audio_sample.wav\"\n",
    "#This model takes as input the data in binary:\n",
    "audio = open(audio_path, 'rb').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 2 (yes)\n",
      "Softmax:\n",
      "[9.07707243e-09 1.17445554e-04 9.95477498e-01 1.50766992e-03\n",
      " 4.08894820e-08 1.28438041e-04 2.74073286e-03 1.82661495e-06\n",
      " 3.72911674e-10 1.27258784e-06 4.47637922e-06 2.07029898e-05]\n"
     ]
    }
   ],
   "source": [
    "softmax = sess.run(softmax_tensor,  feed_dict={input_tensor: audio}).flatten()\n",
    "prediction = np.argmax(softmax)\n",
    "print(\"Predicted class: %d (%s)\"%(prediction, labels[prediction]))\n",
    "print(\"Softmax:\")\n",
    "print(softmax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
